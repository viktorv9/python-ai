{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4.9162 - mae: 4.9162 - val_loss: 7.1734 - val_mae: 7.1734\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.8569 - mae: 4.8569 - val_loss: 7.0752 - val_mae: 7.0752\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.7984 - mae: 4.7984 - val_loss: 6.9803 - val_mae: 6.9803\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.7401 - mae: 4.7401 - val_loss: 6.8904 - val_mae: 6.8904\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.6852 - mae: 4.6852 - val_loss: 6.8020 - val_mae: 6.8020\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.6315 - mae: 4.6315 - val_loss: 6.7179 - val_mae: 6.7179\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.5761 - mae: 4.5761 - val_loss: 6.6394 - val_mae: 6.6394\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.5224 - mae: 4.5224 - val_loss: 6.5597 - val_mae: 6.5597\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.4715 - mae: 4.4715 - val_loss: 6.4767 - val_mae: 6.4767\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.4204 - mae: 4.4204 - val_loss: 6.3972 - val_mae: 6.3972\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.3660 - mae: 4.3660 - val_loss: 6.3252 - val_mae: 6.3252\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.3200 - mae: 4.3200 - val_loss: 6.2502 - val_mae: 6.2502\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.2679 - mae: 4.2679 - val_loss: 6.1763 - val_mae: 6.1763\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.2234 - mae: 4.2234 - val_loss: 6.0993 - val_mae: 6.0993\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.1713 - mae: 4.1713 - val_loss: 6.0356 - val_mae: 6.0356\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.1313 - mae: 4.1313 - val_loss: 5.9638 - val_mae: 5.9638\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0785 - mae: 4.0785 - val_loss: 5.9036 - val_mae: 5.9036\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0310 - mae: 4.0310 - val_loss: 5.8389 - val_mae: 5.8389\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.9888 - mae: 3.9888 - val_loss: 5.7750 - val_mae: 5.7750\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.9439 - mae: 3.9439 - val_loss: 5.7130 - val_mae: 5.7130\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.9011 - mae: 3.9011 - val_loss: 5.6513 - val_mae: 5.6513\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.8572 - mae: 3.8572 - val_loss: 5.5882 - val_mae: 5.5882\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.8185 - mae: 3.8185 - val_loss: 5.5228 - val_mae: 5.5228\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.7734 - mae: 3.7734 - val_loss: 5.4661 - val_mae: 5.4661\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.7290 - mae: 3.7290 - val_loss: 5.4087 - val_mae: 5.4087\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.6921 - mae: 3.6921 - val_loss: 5.3525 - val_mae: 5.3525\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.6532 - mae: 3.6532 - val_loss: 5.2974 - val_mae: 5.2974\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.6131 - mae: 3.6131 - val_loss: 5.2439 - val_mae: 5.2439\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5806 - mae: 3.5806 - val_loss: 5.1931 - val_mae: 5.1931\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5425 - mae: 3.5425 - val_loss: 5.1392 - val_mae: 5.1392\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.5070 - mae: 3.5070 - val_loss: 5.0863 - val_mae: 5.0863\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.4682 - mae: 3.4682 - val_loss: 5.0379 - val_mae: 5.0379\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.4332 - mae: 3.4332 - val_loss: 4.9872 - val_mae: 4.9872\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.4031 - mae: 3.4031 - val_loss: 4.9364 - val_mae: 4.9364\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.3644 - mae: 3.3644 - val_loss: 4.8874 - val_mae: 4.8874\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.3307 - mae: 3.3307 - val_loss: 4.8428 - val_mae: 4.8428\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.3008 - mae: 3.3008 - val_loss: 4.7951 - val_mae: 4.7951\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.2684 - mae: 3.2684 - val_loss: 4.7515 - val_mae: 4.7515\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.2332 - mae: 3.2332 - val_loss: 4.7096 - val_mae: 4.7096\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.2002 - mae: 3.2002 - val_loss: 4.6681 - val_mae: 4.6681\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.1697 - mae: 3.1697 - val_loss: 4.6255 - val_mae: 4.6255\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.1379 - mae: 3.1379 - val_loss: 4.5865 - val_mae: 4.5865\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.1094 - mae: 3.1094 - val_loss: 4.5442 - val_mae: 4.5442\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.0795 - mae: 3.0795 - val_loss: 4.5014 - val_mae: 4.5014\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.0454 - mae: 3.0454 - val_loss: 4.4645 - val_mae: 4.4645\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 3.0190 - mae: 3.0190 - val_loss: 4.4267 - val_mae: 4.4267\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.9873 - mae: 2.9873 - val_loss: 4.3885 - val_mae: 4.3885\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.9601 - mae: 2.9601 - val_loss: 4.3509 - val_mae: 4.3509\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.9298 - mae: 2.9298 - val_loss: 4.3143 - val_mae: 4.3143\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.9023 - mae: 2.9023 - val_loss: 4.2819 - val_mae: 4.2819\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.8744 - mae: 2.8744 - val_loss: 4.2533 - val_mae: 4.2533\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.8469 - mae: 2.8469 - val_loss: 4.2205 - val_mae: 4.2205\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.8219 - mae: 2.8219 - val_loss: 4.1877 - val_mae: 4.1877\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.7902 - mae: 2.7902 - val_loss: 4.1577 - val_mae: 4.1577\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.7651 - mae: 2.7651 - val_loss: 4.1269 - val_mae: 4.1269\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.7404 - mae: 2.7404 - val_loss: 4.0953 - val_mae: 4.0953\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.7142 - mae: 2.7142 - val_loss: 4.0643 - val_mae: 4.0643\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.6869 - mae: 2.6869 - val_loss: 4.0336 - val_mae: 4.0336\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.6608 - mae: 2.6608 - val_loss: 4.0045 - val_mae: 4.0045\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.6381 - mae: 2.6381 - val_loss: 3.9717 - val_mae: 3.9717\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.6112 - mae: 2.6112 - val_loss: 3.9414 - val_mae: 3.9414\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.5865 - mae: 2.5865 - val_loss: 3.9131 - val_mae: 3.9131\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.5644 - mae: 2.5644 - val_loss: 3.8798 - val_mae: 3.8798\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.5379 - mae: 2.5379 - val_loss: 3.8523 - val_mae: 3.8523\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.5166 - mae: 2.5166 - val_loss: 3.8198 - val_mae: 3.8198\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4916 - mae: 2.4916 - val_loss: 3.7928 - val_mae: 3.7928\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4713 - mae: 2.4713 - val_loss: 3.7656 - val_mae: 3.7656\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4530 - mae: 2.4530 - val_loss: 3.7407 - val_mae: 3.7407\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4358 - mae: 2.4358 - val_loss: 3.7140 - val_mae: 3.7140\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4137 - mae: 2.4137 - val_loss: 3.6885 - val_mae: 3.6885\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3946 - mae: 2.3946 - val_loss: 3.6674 - val_mae: 3.6674\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3766 - mae: 2.3766 - val_loss: 3.6415 - val_mae: 3.6415\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3590 - mae: 2.3590 - val_loss: 3.6182 - val_mae: 3.6182\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3425 - mae: 2.3425 - val_loss: 3.5946 - val_mae: 3.5946\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3204 - mae: 2.3204 - val_loss: 3.5697 - val_mae: 3.5697\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3034 - mae: 2.3034 - val_loss: 3.5452 - val_mae: 3.5452\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2863 - mae: 2.2863 - val_loss: 3.5197 - val_mae: 3.5197\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2677 - mae: 2.2677 - val_loss: 3.4955 - val_mae: 3.4955\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2496 - mae: 2.2496 - val_loss: 3.4708 - val_mae: 3.4708\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2328 - mae: 2.2328 - val_loss: 3.4451 - val_mae: 3.4451\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2148 - mae: 2.2148 - val_loss: 3.4208 - val_mae: 3.4208\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1974 - mae: 2.1974 - val_loss: 3.3966 - val_mae: 3.3966\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1809 - mae: 2.1809 - val_loss: 3.3750 - val_mae: 3.3750\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1644 - mae: 2.1644 - val_loss: 3.3508 - val_mae: 3.3508\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1466 - mae: 2.1466 - val_loss: 3.3263 - val_mae: 3.3263\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1297 - mae: 2.1297 - val_loss: 3.3001 - val_mae: 3.3001\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1112 - mae: 2.1112 - val_loss: 3.2781 - val_mae: 3.2781\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0956 - mae: 2.0956 - val_loss: 3.2555 - val_mae: 3.2555\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0790 - mae: 2.0790 - val_loss: 3.2362 - val_mae: 3.2362\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0620 - mae: 2.0620 - val_loss: 3.2146 - val_mae: 3.2146\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0476 - mae: 2.0476 - val_loss: 3.1924 - val_mae: 3.1924\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0312 - mae: 2.0312 - val_loss: 3.1651 - val_mae: 3.1651\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0146 - mae: 2.0146 - val_loss: 3.1336 - val_mae: 3.1336\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0006 - mae: 2.0006 - val_loss: 3.1046 - val_mae: 3.1046\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9878 - mae: 1.9878 - val_loss: 3.0790 - val_mae: 3.0790\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9720 - mae: 1.9720 - val_loss: 3.0506 - val_mae: 3.0506\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9592 - mae: 1.9592 - val_loss: 3.0341 - val_mae: 3.0341\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9508 - mae: 1.9508 - val_loss: 3.0277 - val_mae: 3.0277\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9413 - mae: 1.9413 - val_loss: 3.0159 - val_mae: 3.0159\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9309 - mae: 1.9309 - val_loss: 3.0117 - val_mae: 3.0117\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9213 - mae: 1.9213 - val_loss: 3.0058 - val_mae: 3.0058\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9115 - mae: 1.9115 - val_loss: 3.0077 - val_mae: 3.0077\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9038 - mae: 1.9038 - val_loss: 3.0051 - val_mae: 3.0051\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8936 - mae: 1.8936 - val_loss: 3.0031 - val_mae: 3.0031\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8839 - mae: 1.8839 - val_loss: 3.0017 - val_mae: 3.0017\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8763 - mae: 1.8763 - val_loss: 3.0031 - val_mae: 3.0031\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8654 - mae: 1.8654 - val_loss: 3.0031 - val_mae: 3.0031\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8575 - mae: 1.8575 - val_loss: 2.9996 - val_mae: 2.9996\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8494 - mae: 1.8494 - val_loss: 3.0042 - val_mae: 3.0042\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8417 - mae: 1.8417 - val_loss: 3.0040 - val_mae: 3.0040\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8364 - mae: 1.8364 - val_loss: 2.9962 - val_mae: 2.9962\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8282 - mae: 1.8282 - val_loss: 2.9967 - val_mae: 2.9967\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8225 - mae: 1.8225 - val_loss: 2.9909 - val_mae: 2.9909\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8141 - mae: 1.8141 - val_loss: 2.9897 - val_mae: 2.9897\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8071 - mae: 1.8071 - val_loss: 2.9949 - val_mae: 2.9949\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8014 - mae: 1.8014 - val_loss: 2.9932 - val_mae: 2.9932\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7957 - mae: 1.7957 - val_loss: 2.9877 - val_mae: 2.9877\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7889 - mae: 1.7889 - val_loss: 2.9871 - val_mae: 2.9871\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7844 - mae: 1.7844 - val_loss: 2.9866 - val_mae: 2.9866\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7782 - mae: 1.7782 - val_loss: 2.9854 - val_mae: 2.9854\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7728 - mae: 1.7728 - val_loss: 2.9830 - val_mae: 2.9830\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7675 - mae: 1.7675 - val_loss: 2.9773 - val_mae: 2.9773\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7621 - mae: 1.7621 - val_loss: 2.9810 - val_mae: 2.9810\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7567 - mae: 1.7567 - val_loss: 2.9762 - val_mae: 2.9762\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7519 - mae: 1.7519 - val_loss: 2.9751 - val_mae: 2.9751\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7484 - mae: 1.7484 - val_loss: 2.9713 - val_mae: 2.9713\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7429 - mae: 1.7429 - val_loss: 2.9704 - val_mae: 2.9704\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7397 - mae: 1.7397 - val_loss: 2.9672 - val_mae: 2.9672\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7355 - mae: 1.7355 - val_loss: 2.9617 - val_mae: 2.9617\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7305 - mae: 1.7305 - val_loss: 2.9599 - val_mae: 2.9599\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7268 - mae: 1.7268 - val_loss: 2.9609 - val_mae: 2.9609\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7222 - mae: 1.7222 - val_loss: 2.9573 - val_mae: 2.9573\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7182 - mae: 1.7182 - val_loss: 2.9567 - val_mae: 2.9567\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.7149 - mae: 1.7149 - val_loss: 2.9502 - val_mae: 2.9502\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7107 - mae: 1.7107 - val_loss: 2.9489 - val_mae: 2.9489\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7081 - mae: 1.7081 - val_loss: 2.9478 - val_mae: 2.9478\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7063 - mae: 1.7063 - val_loss: 2.9457 - val_mae: 2.9457\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7037 - mae: 1.7037 - val_loss: 2.9477 - val_mae: 2.9477\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7015 - mae: 1.7015 - val_loss: 2.9488 - val_mae: 2.9488\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6992 - mae: 1.6992 - val_loss: 2.9501 - val_mae: 2.9501\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6971 - mae: 1.6971 - val_loss: 2.9468 - val_mae: 2.9468\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6952 - mae: 1.6952 - val_loss: 2.9476 - val_mae: 2.9476\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6930 - mae: 1.6930 - val_loss: 2.9443 - val_mae: 2.9443\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6906 - mae: 1.6906 - val_loss: 2.9467 - val_mae: 2.9467\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6892 - mae: 1.6892 - val_loss: 2.9416 - val_mae: 2.9416\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6872 - mae: 1.6872 - val_loss: 2.9470 - val_mae: 2.9470\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6861 - mae: 1.6861 - val_loss: 2.9438 - val_mae: 2.9438\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6842 - mae: 1.6842 - val_loss: 2.9433 - val_mae: 2.9433\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6818 - mae: 1.6818 - val_loss: 2.9432 - val_mae: 2.9432\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6802 - mae: 1.6802 - val_loss: 2.9403 - val_mae: 2.9403\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6790 - mae: 1.6790 - val_loss: 2.9386 - val_mae: 2.9386\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6766 - mae: 1.6766 - val_loss: 2.9401 - val_mae: 2.9401\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6752 - mae: 1.6752 - val_loss: 2.9367 - val_mae: 2.9367\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6736 - mae: 1.6736 - val_loss: 2.9350 - val_mae: 2.9350\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6717 - mae: 1.6717 - val_loss: 2.9367 - val_mae: 2.9367\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6701 - mae: 1.6701 - val_loss: 2.9362 - val_mae: 2.9362\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6688 - mae: 1.6688 - val_loss: 2.9352 - val_mae: 2.9352\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6664 - mae: 1.6664 - val_loss: 2.9383 - val_mae: 2.9383\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6655 - mae: 1.6655 - val_loss: 2.9327 - val_mae: 2.9327\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6631 - mae: 1.6631 - val_loss: 2.9327 - val_mae: 2.9327\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6613 - mae: 1.6613 - val_loss: 2.9336 - val_mae: 2.9336\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6597 - mae: 1.6597 - val_loss: 2.9326 - val_mae: 2.9326\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6592 - mae: 1.6592 - val_loss: 2.9285 - val_mae: 2.9285\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6565 - mae: 1.6565 - val_loss: 2.9278 - val_mae: 2.9278\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6542 - mae: 1.6542 - val_loss: 2.9273 - val_mae: 2.9273\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6528 - mae: 1.6528 - val_loss: 2.9277 - val_mae: 2.9277\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6509 - mae: 1.6509 - val_loss: 2.9281 - val_mae: 2.9281\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6497 - mae: 1.6497 - val_loss: 2.9212 - val_mae: 2.9212\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6474 - mae: 1.6474 - val_loss: 2.9206 - val_mae: 2.9206\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6454 - mae: 1.6454 - val_loss: 2.9211 - val_mae: 2.9211\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6435 - mae: 1.6435 - val_loss: 2.9180 - val_mae: 2.9180\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6419 - mae: 1.6419 - val_loss: 2.9136 - val_mae: 2.9136\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6401 - mae: 1.6401 - val_loss: 2.9097 - val_mae: 2.9097\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6379 - mae: 1.6379 - val_loss: 2.9103 - val_mae: 2.9103\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6367 - mae: 1.6367 - val_loss: 2.9032 - val_mae: 2.9032\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6345 - mae: 1.6345 - val_loss: 2.9007 - val_mae: 2.9007\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6329 - mae: 1.6329 - val_loss: 2.8980 - val_mae: 2.8980\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6307 - mae: 1.6307 - val_loss: 2.8959 - val_mae: 2.8959\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6297 - mae: 1.6297 - val_loss: 2.8928 - val_mae: 2.8928\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6276 - mae: 1.6276 - val_loss: 2.8903 - val_mae: 2.8903\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6256 - mae: 1.6256 - val_loss: 2.8857 - val_mae: 2.8857\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6237 - mae: 1.6237 - val_loss: 2.8831 - val_mae: 2.8831\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6224 - mae: 1.6224 - val_loss: 2.8756 - val_mae: 2.8756\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6209 - mae: 1.6209 - val_loss: 2.8728 - val_mae: 2.8728\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6187 - mae: 1.6187 - val_loss: 2.8667 - val_mae: 2.8667\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6169 - mae: 1.6169 - val_loss: 2.8636 - val_mae: 2.8636\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6156 - mae: 1.6156 - val_loss: 2.8562 - val_mae: 2.8562\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6133 - mae: 1.6133 - val_loss: 2.8534 - val_mae: 2.8534\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6115 - mae: 1.6115 - val_loss: 2.8538 - val_mae: 2.8538\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6097 - mae: 1.6097 - val_loss: 2.8455 - val_mae: 2.8455\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6077 - mae: 1.6077 - val_loss: 2.8392 - val_mae: 2.8392\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6053 - mae: 1.6053 - val_loss: 2.8321 - val_mae: 2.8321\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6034 - mae: 1.6034 - val_loss: 2.8243 - val_mae: 2.8243\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6015 - mae: 1.6015 - val_loss: 2.8135 - val_mae: 2.8135\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5987 - mae: 1.5987 - val_loss: 2.8080 - val_mae: 2.8080\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5967 - mae: 1.5967 - val_loss: 2.7970 - val_mae: 2.7970\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5946 - mae: 1.5946 - val_loss: 2.7863 - val_mae: 2.7863\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5909 - mae: 1.5909 - val_loss: 2.7779 - val_mae: 2.7779\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5879 - mae: 1.5879 - val_loss: 2.7653 - val_mae: 2.7653\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5847 - mae: 1.5847 - val_loss: 2.7508 - val_mae: 2.7508\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5809 - mae: 1.5809 - val_loss: 2.7380 - val_mae: 2.7380\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5782 - mae: 1.5782 - val_loss: 2.7159 - val_mae: 2.7159\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5739 - mae: 1.5739 - val_loss: 2.6911 - val_mae: 2.6911\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5692 - mae: 1.5692 - val_loss: 2.6718 - val_mae: 2.6718\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5651 - mae: 1.5651 - val_loss: 2.6469 - val_mae: 2.6469\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5605 - mae: 1.5605 - val_loss: 2.6196 - val_mae: 2.6196\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5549 - mae: 1.5549 - val_loss: 2.5928 - val_mae: 2.5928\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5496 - mae: 1.5496 - val_loss: 2.5674 - val_mae: 2.5674\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5438 - mae: 1.5438 - val_loss: 2.5359 - val_mae: 2.5359\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5403 - mae: 1.5403 - val_loss: 2.4960 - val_mae: 2.4960\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5310 - mae: 1.5310 - val_loss: 2.4653 - val_mae: 2.4653\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5218 - mae: 1.5218 - val_loss: 2.4340 - val_mae: 2.4340\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5127 - mae: 1.5127 - val_loss: 2.3815 - val_mae: 2.3815\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4947 - mae: 1.4947 - val_loss: 2.3416 - val_mae: 2.3416\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4783 - mae: 1.4783 - val_loss: 2.2999 - val_mae: 2.2999\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4618 - mae: 1.4618 - val_loss: 2.2405 - val_mae: 2.2405\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4434 - mae: 1.4434 - val_loss: 2.1760 - val_mae: 2.1760\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4236 - mae: 1.4236 - val_loss: 2.1017 - val_mae: 2.1017\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3964 - mae: 1.3964 - val_loss: 2.0375 - val_mae: 2.0375\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3740 - mae: 1.3740 - val_loss: 1.9582 - val_mae: 1.9582\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3449 - mae: 1.3449 - val_loss: 1.8827 - val_mae: 1.8827\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3180 - mae: 1.3180 - val_loss: 1.7930 - val_mae: 1.7930\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.2842 - mae: 1.2842 - val_loss: 1.7154 - val_mae: 1.7154\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.2532 - mae: 1.2532 - val_loss: 1.6221 - val_mae: 1.6221\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.2195 - mae: 1.2195 - val_loss: 1.5186 - val_mae: 1.5186\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1885 - mae: 1.1885 - val_loss: 1.4040 - val_mae: 1.4040\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1423 - mae: 1.1423 - val_loss: 1.3346 - val_mae: 1.3346\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1254 - mae: 1.1254 - val_loss: 1.2426 - val_mae: 1.2426\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0950 - mae: 1.0950 - val_loss: 1.1731 - val_mae: 1.1731\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0697 - mae: 1.0697 - val_loss: 1.1175 - val_mae: 1.1175\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0501 - mae: 1.0501 - val_loss: 1.0352 - val_mae: 1.0352\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0261 - mae: 1.0261 - val_loss: 0.9448 - val_mae: 0.9448\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9905 - mae: 0.9905 - val_loss: 0.8907 - val_mae: 0.8907\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9721 - mae: 0.9721 - val_loss: 0.8275 - val_mae: 0.8275\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9407 - mae: 0.9407 - val_loss: 0.7907 - val_mae: 0.7907\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9258 - mae: 0.9258 - val_loss: 0.7547 - val_mae: 0.7547\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9162 - mae: 0.9162 - val_loss: 0.7007 - val_mae: 0.7007\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8938 - mae: 0.8938 - val_loss: 0.6752 - val_mae: 0.6752\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8818 - mae: 0.8818 - val_loss: 0.6303 - val_mae: 0.6303\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8673 - mae: 0.8673 - val_loss: 0.5824 - val_mae: 0.5824\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8514 - mae: 0.8514 - val_loss: 0.5390 - val_mae: 0.5390\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8299 - mae: 0.8299 - val_loss: 0.5109 - val_mae: 0.5109\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8160 - mae: 0.8160 - val_loss: 0.4893 - val_mae: 0.4893\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8056 - mae: 0.8056 - val_loss: 0.4680 - val_mae: 0.4680\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7826 - mae: 0.7826 - val_loss: 0.4532 - val_mae: 0.4532\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7687 - mae: 0.7687 - val_loss: 0.4417 - val_mae: 0.4417\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7638 - mae: 0.7638 - val_loss: 0.4327 - val_mae: 0.4327\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7579 - mae: 0.7579 - val_loss: 0.4285 - val_mae: 0.4285\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7513 - mae: 0.7513 - val_loss: 0.4201 - val_mae: 0.4201\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7454 - mae: 0.7454 - val_loss: 0.4124 - val_mae: 0.4124\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7401 - mae: 0.7401 - val_loss: 0.4069 - val_mae: 0.4069\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7351 - mae: 0.7351 - val_loss: 0.4041 - val_mae: 0.4041\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7278 - mae: 0.7278 - val_loss: 0.3994 - val_mae: 0.3994\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7234 - mae: 0.7234 - val_loss: 0.3970 - val_mae: 0.3970\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7162 - mae: 0.7162 - val_loss: 0.3939 - val_mae: 0.3939\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7120 - mae: 0.7120 - val_loss: 0.3916 - val_mae: 0.3916\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7047 - mae: 0.7047 - val_loss: 0.3880 - val_mae: 0.3880\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6982 - mae: 0.6982 - val_loss: 0.3830 - val_mae: 0.3830\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6938 - mae: 0.6938 - val_loss: 0.3799 - val_mae: 0.3799\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6859 - mae: 0.6859 - val_loss: 0.3749 - val_mae: 0.3749\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6826 - mae: 0.6826 - val_loss: 0.3684 - val_mae: 0.3684\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6758 - mae: 0.6758 - val_loss: 0.3662 - val_mae: 0.3662\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6705 - mae: 0.6705 - val_loss: 0.3635 - val_mae: 0.3635\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6641 - mae: 0.6641 - val_loss: 0.3591 - val_mae: 0.3591\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6619 - mae: 0.6619 - val_loss: 0.3561 - val_mae: 0.3561\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6568 - mae: 0.6568 - val_loss: 0.3504 - val_mae: 0.3504\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6538 - mae: 0.6538 - val_loss: 0.3456 - val_mae: 0.3456\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6508 - mae: 0.6508 - val_loss: 0.3415 - val_mae: 0.3415\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6447 - mae: 0.6447 - val_loss: 0.3378 - val_mae: 0.3378\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6435 - mae: 0.6435 - val_loss: 0.3325 - val_mae: 0.3325\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6388 - mae: 0.6388 - val_loss: 0.3298 - val_mae: 0.3298\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6339 - mae: 0.6339 - val_loss: 0.3261 - val_mae: 0.3261\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6318 - mae: 0.6318 - val_loss: 0.3218 - val_mae: 0.3218\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6288 - mae: 0.6288 - val_loss: 0.3189 - val_mae: 0.3189\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6268 - mae: 0.6268 - val_loss: 0.3132 - val_mae: 0.3132\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6212 - mae: 0.6212 - val_loss: 0.3093 - val_mae: 0.3093\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6170 - mae: 0.6170 - val_loss: 0.3067 - val_mae: 0.3067\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6143 - mae: 0.6143 - val_loss: 0.3033 - val_mae: 0.3033\n",
      "Epoch 279/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6103 - mae: 0.6103 - val_loss: 0.2997 - val_mae: 0.2997\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6081 - mae: 0.6081 - val_loss: 0.2958 - val_mae: 0.2958\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6043 - mae: 0.6043 - val_loss: 0.2922 - val_mae: 0.2922\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6008 - mae: 0.6008 - val_loss: 0.2877 - val_mae: 0.2877\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5983 - mae: 0.5983 - val_loss: 0.2847 - val_mae: 0.2847\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5952 - mae: 0.5952 - val_loss: 0.2819 - val_mae: 0.2819\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5924 - mae: 0.5924 - val_loss: 0.2765 - val_mae: 0.2765\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5883 - mae: 0.5883 - val_loss: 0.2730 - val_mae: 0.2730\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5851 - mae: 0.5851 - val_loss: 0.2699 - val_mae: 0.2699\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5818 - mae: 0.5818 - val_loss: 0.2647 - val_mae: 0.2647\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5784 - mae: 0.5784 - val_loss: 0.2648 - val_mae: 0.2648\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5742 - mae: 0.5742 - val_loss: 0.2629 - val_mae: 0.2629\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5710 - mae: 0.5710 - val_loss: 0.2641 - val_mae: 0.2641\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5680 - mae: 0.5680 - val_loss: 0.2615 - val_mae: 0.2615\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5644 - mae: 0.5644 - val_loss: 0.2617 - val_mae: 0.2617\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5611 - mae: 0.5611 - val_loss: 0.2632 - val_mae: 0.2632\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5578 - mae: 0.5578 - val_loss: 0.2643 - val_mae: 0.2643\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5558 - mae: 0.5558 - val_loss: 0.2717 - val_mae: 0.2717\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5520 - mae: 0.5520 - val_loss: 0.2675 - val_mae: 0.2675\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5493 - mae: 0.5493 - val_loss: 0.2735 - val_mae: 0.2735\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5467 - mae: 0.5467 - val_loss: 0.2673 - val_mae: 0.2673\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5463 - mae: 0.5463 - val_loss: 0.2619 - val_mae: 0.2619\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5435 - mae: 0.5435 - val_loss: 0.2786 - val_mae: 0.2786\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5386 - mae: 0.5386 - val_loss: 0.2774 - val_mae: 0.2774\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5369 - mae: 0.5369 - val_loss: 0.2826 - val_mae: 0.2826\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5342 - mae: 0.5342 - val_loss: 0.2756 - val_mae: 0.2756\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5317 - mae: 0.5317 - val_loss: 0.2845 - val_mae: 0.2845\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5276 - mae: 0.5276 - val_loss: 0.2866 - val_mae: 0.2866\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5251 - mae: 0.5251 - val_loss: 0.2801 - val_mae: 0.2801\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5248 - mae: 0.5248 - val_loss: 0.2921 - val_mae: 0.2921\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5196 - mae: 0.5196 - val_loss: 0.2919 - val_mae: 0.2919\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5171 - mae: 0.5171 - val_loss: 0.2947 - val_mae: 0.2947\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5140 - mae: 0.5140 - val_loss: 0.2967 - val_mae: 0.2967\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5108 - mae: 0.5108 - val_loss: 0.2958 - val_mae: 0.2958\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5085 - mae: 0.5085 - val_loss: 0.2953 - val_mae: 0.2953\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5065 - mae: 0.5065 - val_loss: 0.3008 - val_mae: 0.3008\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5052 - mae: 0.5052 - val_loss: 0.3099 - val_mae: 0.3099\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5021 - mae: 0.5021 - val_loss: 0.3015 - val_mae: 0.3015\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4986 - mae: 0.4986 - val_loss: 0.3073 - val_mae: 0.3073\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4954 - mae: 0.4954 - val_loss: 0.3102 - val_mae: 0.3102\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4934 - mae: 0.4934 - val_loss: 0.3124 - val_mae: 0.3124\n",
      "Epoch 320/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4899 - mae: 0.4899 - val_loss: 0.3122 - val_mae: 0.3122\n",
      "Epoch 321/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4879 - mae: 0.4879 - val_loss: 0.3064 - val_mae: 0.3064\n",
      "Epoch 322/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4858 - mae: 0.4858 - val_loss: 0.3015 - val_mae: 0.3015\n",
      "Epoch 323/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4830 - mae: 0.4830 - val_loss: 0.3006 - val_mae: 0.3006\n",
      "Epoch 324/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4809 - mae: 0.4809 - val_loss: 0.3096 - val_mae: 0.3096\n",
      "Epoch 325/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4771 - mae: 0.4771 - val_loss: 0.3119 - val_mae: 0.3119\n",
      "Epoch 326/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4742 - mae: 0.4742 - val_loss: 0.3167 - val_mae: 0.3167\n",
      "Epoch 327/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4720 - mae: 0.4720 - val_loss: 0.3159 - val_mae: 0.3159\n",
      "Epoch 328/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4684 - mae: 0.4684 - val_loss: 0.3216 - val_mae: 0.3216\n",
      "Epoch 329/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4668 - mae: 0.4668 - val_loss: 0.3296 - val_mae: 0.3296\n",
      "Epoch 330/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4634 - mae: 0.4634 - val_loss: 0.3320 - val_mae: 0.3320\n",
      "Epoch 331/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4605 - mae: 0.4605 - val_loss: 0.3292 - val_mae: 0.3292\n",
      "Epoch 332/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4576 - mae: 0.4576 - val_loss: 0.3305 - val_mae: 0.3305\n",
      "Epoch 333/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4554 - mae: 0.4554 - val_loss: 0.3388 - val_mae: 0.3388\n",
      "Epoch 334/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4520 - mae: 0.4520 - val_loss: 0.3378 - val_mae: 0.3378\n",
      "Epoch 335/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4505 - mae: 0.4505 - val_loss: 0.3393 - val_mae: 0.3393\n",
      "Epoch 336/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4477 - mae: 0.4477 - val_loss: 0.3399 - val_mae: 0.3399\n",
      "Epoch 337/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4444 - mae: 0.4444 - val_loss: 0.3432 - val_mae: 0.3432\n",
      "Epoch 338/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4416 - mae: 0.4416 - val_loss: 0.3419 - val_mae: 0.3419\n",
      "Epoch 339/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4398 - mae: 0.4398 - val_loss: 0.3540 - val_mae: 0.3540\n",
      "Epoch 340/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4367 - mae: 0.4367 - val_loss: 0.3503 - val_mae: 0.3503\n",
      "Epoch 341/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4336 - mae: 0.4336 - val_loss: 0.3609 - val_mae: 0.3609\n",
      "Epoch 342/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4308 - mae: 0.4308 - val_loss: 0.3558 - val_mae: 0.3558\n",
      "Epoch 343/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4287 - mae: 0.4287 - val_loss: 0.3569 - val_mae: 0.3569\n",
      "Epoch 344/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4260 - mae: 0.4260 - val_loss: 0.3715 - val_mae: 0.3715\n",
      "Epoch 345/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4224 - mae: 0.4224 - val_loss: 0.3756 - val_mae: 0.3756\n",
      "Epoch 346/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4202 - mae: 0.4202 - val_loss: 0.3801 - val_mae: 0.3801\n",
      "Epoch 347/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4167 - mae: 0.4167 - val_loss: 0.3814 - val_mae: 0.3814\n",
      "Epoch 348/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4140 - mae: 0.4140 - val_loss: 0.3868 - val_mae: 0.3868\n",
      "Epoch 349/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4118 - mae: 0.4118 - val_loss: 0.3843 - val_mae: 0.3843\n",
      "Epoch 350/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4085 - mae: 0.4085 - val_loss: 0.3908 - val_mae: 0.3908\n",
      "Epoch 351/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4062 - mae: 0.4062 - val_loss: 0.3958 - val_mae: 0.3958\n",
      "Epoch 352/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4034 - mae: 0.4034 - val_loss: 0.4100 - val_mae: 0.4100\n",
      "Epoch 353/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4008 - mae: 0.4008 - val_loss: 0.4136 - val_mae: 0.4136\n",
      "Epoch 354/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3981 - mae: 0.3981 - val_loss: 0.4121 - val_mae: 0.4121\n",
      "Epoch 355/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3963 - mae: 0.3963 - val_loss: 0.4104 - val_mae: 0.4104\n",
      "Epoch 356/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3924 - mae: 0.3924 - val_loss: 0.4137 - val_mae: 0.4137\n",
      "Epoch 357/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3894 - mae: 0.3894 - val_loss: 0.4231 - val_mae: 0.4231\n",
      "Epoch 358/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3879 - mae: 0.3879 - val_loss: 0.4317 - val_mae: 0.4317\n",
      "Epoch 359/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3865 - mae: 0.3865 - val_loss: 0.4110 - val_mae: 0.4110\n",
      "Epoch 360/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3829 - mae: 0.3829 - val_loss: 0.4091 - val_mae: 0.4091\n",
      "Epoch 361/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3801 - mae: 0.3801 - val_loss: 0.4183 - val_mae: 0.4183\n",
      "Epoch 362/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3771 - mae: 0.3771 - val_loss: 0.4227 - val_mae: 0.4227\n",
      "Epoch 363/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3740 - mae: 0.3740 - val_loss: 0.4130 - val_mae: 0.4130\n",
      "Epoch 364/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3732 - mae: 0.3732 - val_loss: 0.4099 - val_mae: 0.4099\n",
      "Epoch 365/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3693 - mae: 0.3693 - val_loss: 0.4156 - val_mae: 0.4156\n",
      "Epoch 366/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3668 - mae: 0.3668 - val_loss: 0.4241 - val_mae: 0.4241\n",
      "Epoch 367/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3645 - mae: 0.3645 - val_loss: 0.4250 - val_mae: 0.4250\n",
      "Epoch 368/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3612 - mae: 0.3612 - val_loss: 0.4387 - val_mae: 0.4387\n",
      "Epoch 369/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3604 - mae: 0.3604 - val_loss: 0.4391 - val_mae: 0.4391\n",
      "Epoch 370/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3575 - mae: 0.3575 - val_loss: 0.4274 - val_mae: 0.4274\n",
      "Epoch 371/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3537 - mae: 0.3537 - val_loss: 0.4255 - val_mae: 0.4255\n",
      "Epoch 372/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3519 - mae: 0.3519 - val_loss: 0.4320 - val_mae: 0.4320\n",
      "Epoch 373/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3490 - mae: 0.3490 - val_loss: 0.4292 - val_mae: 0.4292\n",
      "Epoch 374/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3471 - mae: 0.3471 - val_loss: 0.4260 - val_mae: 0.4260\n",
      "Epoch 375/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3438 - mae: 0.3438 - val_loss: 0.4375 - val_mae: 0.4375\n",
      "Epoch 376/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3402 - mae: 0.3402 - val_loss: 0.4297 - val_mae: 0.4297\n",
      "Epoch 377/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3431 - mae: 0.3431 - val_loss: 0.4077 - val_mae: 0.4077\n",
      "Epoch 378/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3357 - mae: 0.3357 - val_loss: 0.4143 - val_mae: 0.4143\n",
      "Epoch 379/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3322 - mae: 0.3322 - val_loss: 0.4193 - val_mae: 0.4193\n",
      "Epoch 380/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3294 - mae: 0.3294 - val_loss: 0.4247 - val_mae: 0.4247\n",
      "Epoch 381/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3268 - mae: 0.3268 - val_loss: 0.4360 - val_mae: 0.4360\n",
      "Epoch 382/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3258 - mae: 0.3258 - val_loss: 0.4255 - val_mae: 0.4255\n",
      "Epoch 383/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3220 - mae: 0.3220 - val_loss: 0.4345 - val_mae: 0.4345\n",
      "Epoch 384/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3201 - mae: 0.3201 - val_loss: 0.4384 - val_mae: 0.4384\n",
      "Epoch 385/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3163 - mae: 0.3163 - val_loss: 0.4314 - val_mae: 0.4314\n",
      "Epoch 386/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3133 - mae: 0.3133 - val_loss: 0.4323 - val_mae: 0.4323\n",
      "Epoch 387/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3117 - mae: 0.3117 - val_loss: 0.4407 - val_mae: 0.4407\n",
      "Epoch 388/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3092 - mae: 0.3092 - val_loss: 0.4377 - val_mae: 0.4377\n",
      "Epoch 389/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3061 - mae: 0.3061 - val_loss: 0.4444 - val_mae: 0.4444\n",
      "Epoch 390/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3046 - mae: 0.3046 - val_loss: 0.4308 - val_mae: 0.4308\n",
      "Epoch 391/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3006 - mae: 0.3006 - val_loss: 0.4465 - val_mae: 0.4465\n",
      "Epoch 392/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2978 - mae: 0.2978 - val_loss: 0.4452 - val_mae: 0.4452\n",
      "Epoch 393/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2960 - mae: 0.2960 - val_loss: 0.4327 - val_mae: 0.4327\n",
      "Epoch 394/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2917 - mae: 0.2917 - val_loss: 0.4387 - val_mae: 0.4387\n",
      "Epoch 395/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2900 - mae: 0.2900 - val_loss: 0.4468 - val_mae: 0.4468\n",
      "Epoch 396/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2861 - mae: 0.2861 - val_loss: 0.4372 - val_mae: 0.4372\n",
      "Epoch 397/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2839 - mae: 0.2839 - val_loss: 0.4463 - val_mae: 0.4463\n",
      "Epoch 398/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2809 - mae: 0.2809 - val_loss: 0.4376 - val_mae: 0.4376\n",
      "Epoch 399/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2802 - mae: 0.2802 - val_loss: 0.4296 - val_mae: 0.4296\n",
      "Epoch 400/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2764 - mae: 0.2764 - val_loss: 0.4311 - val_mae: 0.4311\n",
      "Epoch 401/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2735 - mae: 0.2735 - val_loss: 0.4473 - val_mae: 0.4473\n",
      "Epoch 402/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2704 - mae: 0.2704 - val_loss: 0.4356 - val_mae: 0.4356\n",
      "Epoch 403/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2679 - mae: 0.2679 - val_loss: 0.4349 - val_mae: 0.4349\n",
      "Epoch 404/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2643 - mae: 0.2643 - val_loss: 0.4394 - val_mae: 0.4394\n",
      "Epoch 405/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2618 - mae: 0.2618 - val_loss: 0.4506 - val_mae: 0.4506\n",
      "Epoch 406/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2592 - mae: 0.2592 - val_loss: 0.4527 - val_mae: 0.4527\n",
      "Epoch 407/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2564 - mae: 0.2564 - val_loss: 0.4468 - val_mae: 0.4468\n",
      "Epoch 408/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2532 - mae: 0.2532 - val_loss: 0.4453 - val_mae: 0.4453\n",
      "Epoch 409/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2525 - mae: 0.2525 - val_loss: 0.4331 - val_mae: 0.4331\n",
      "Epoch 410/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2508 - mae: 0.2508 - val_loss: 0.4517 - val_mae: 0.4517\n",
      "Epoch 411/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2471 - mae: 0.2471 - val_loss: 0.4298 - val_mae: 0.4298\n",
      "Epoch 412/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2427 - mae: 0.2427 - val_loss: 0.4311 - val_mae: 0.4311\n",
      "Epoch 413/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2412 - mae: 0.2412 - val_loss: 0.4451 - val_mae: 0.4451\n",
      "Epoch 414/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2374 - mae: 0.2374 - val_loss: 0.4553 - val_mae: 0.4553\n",
      "Epoch 415/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2335 - mae: 0.2335 - val_loss: 0.4498 - val_mae: 0.4498\n",
      "Epoch 416/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2314 - mae: 0.2314 - val_loss: 0.4535 - val_mae: 0.4535\n",
      "Epoch 417/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2296 - mae: 0.2296 - val_loss: 0.4441 - val_mae: 0.4441\n",
      "Epoch 418/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2280 - mae: 0.2280 - val_loss: 0.4565 - val_mae: 0.4565\n",
      "Epoch 419/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2245 - mae: 0.2245 - val_loss: 0.4587 - val_mae: 0.4587\n",
      "Epoch 420/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2218 - mae: 0.2218 - val_loss: 0.4451 - val_mae: 0.4451\n",
      "Epoch 421/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2195 - mae: 0.2195 - val_loss: 0.4488 - val_mae: 0.4488\n",
      "Epoch 422/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2175 - mae: 0.2175 - val_loss: 0.4641 - val_mae: 0.4641\n",
      "Epoch 423/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2175 - mae: 0.2175 - val_loss: 0.4631 - val_mae: 0.4631\n",
      "Epoch 424/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2145 - mae: 0.2145 - val_loss: 0.4558 - val_mae: 0.4558\n",
      "Epoch 425/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2104 - mae: 0.2104 - val_loss: 0.4423 - val_mae: 0.4423\n",
      "Epoch 426/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2090 - mae: 0.2090 - val_loss: 0.4398 - val_mae: 0.4398\n",
      "Epoch 427/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2077 - mae: 0.2077 - val_loss: 0.4392 - val_mae: 0.4392\n",
      "Epoch 428/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2057 - mae: 0.2057 - val_loss: 0.4298 - val_mae: 0.4298\n",
      "Epoch 429/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2024 - mae: 0.2024 - val_loss: 0.4367 - val_mae: 0.4367\n",
      "Epoch 430/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2003 - mae: 0.2003 - val_loss: 0.4315 - val_mae: 0.4315\n",
      "Epoch 431/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1976 - mae: 0.1976 - val_loss: 0.4173 - val_mae: 0.4173\n",
      "Epoch 432/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1995 - mae: 0.1995 - val_loss: 0.4019 - val_mae: 0.4019\n",
      "Epoch 433/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1977 - mae: 0.1977 - val_loss: 0.4306 - val_mae: 0.4306\n",
      "Epoch 434/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1917 - mae: 0.1917 - val_loss: 0.4297 - val_mae: 0.4297\n",
      "Epoch 435/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1903 - mae: 0.1903 - val_loss: 0.4287 - val_mae: 0.4287\n",
      "Epoch 436/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1884 - mae: 0.1884 - val_loss: 0.4120 - val_mae: 0.4120\n",
      "Epoch 437/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1856 - mae: 0.1856 - val_loss: 0.4056 - val_mae: 0.4056\n",
      "Epoch 438/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1838 - mae: 0.1838 - val_loss: 0.4171 - val_mae: 0.4171\n",
      "Epoch 439/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1814 - mae: 0.1814 - val_loss: 0.4085 - val_mae: 0.4085\n",
      "Epoch 440/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1786 - mae: 0.1786 - val_loss: 0.4075 - val_mae: 0.4075\n",
      "Epoch 441/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1768 - mae: 0.1768 - val_loss: 0.4067 - val_mae: 0.4067\n",
      "Epoch 442/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1792 - mae: 0.1792 - val_loss: 0.3848 - val_mae: 0.3848\n",
      "Epoch 443/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1752 - mae: 0.1752 - val_loss: 0.3986 - val_mae: 0.3986\n",
      "Epoch 444/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1701 - mae: 0.1701 - val_loss: 0.3935 - val_mae: 0.3935\n",
      "Epoch 445/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1679 - mae: 0.1679 - val_loss: 0.3865 - val_mae: 0.3865\n",
      "Epoch 446/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1687 - mae: 0.1687 - val_loss: 0.3989 - val_mae: 0.3989\n",
      "Epoch 447/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1645 - mae: 0.1645 - val_loss: 0.3801 - val_mae: 0.3801\n",
      "Epoch 448/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1617 - mae: 0.1617 - val_loss: 0.3761 - val_mae: 0.3761\n",
      "Epoch 449/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.3751 - val_mae: 0.3751\n",
      "Epoch 450/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1572 - mae: 0.1572 - val_loss: 0.3819 - val_mae: 0.3819\n",
      "Epoch 451/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1558 - mae: 0.1558 - val_loss: 0.3810 - val_mae: 0.3810\n",
      "Epoch 452/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1539 - mae: 0.1539 - val_loss: 0.3659 - val_mae: 0.3659\n",
      "Epoch 453/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1508 - mae: 0.1508 - val_loss: 0.3661 - val_mae: 0.3661\n",
      "Epoch 454/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1494 - mae: 0.1494 - val_loss: 0.3678 - val_mae: 0.3678\n",
      "Epoch 455/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1467 - mae: 0.1467 - val_loss: 0.3560 - val_mae: 0.3560\n",
      "Epoch 456/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1436 - mae: 0.1436 - val_loss: 0.3555 - val_mae: 0.3555\n",
      "Epoch 457/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1416 - mae: 0.1416 - val_loss: 0.3484 - val_mae: 0.3484\n",
      "Epoch 458/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1396 - mae: 0.1396 - val_loss: 0.3476 - val_mae: 0.3476\n",
      "Epoch 459/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1373 - mae: 0.1373 - val_loss: 0.3442 - val_mae: 0.3442\n",
      "Epoch 460/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1369 - mae: 0.1369 - val_loss: 0.3425 - val_mae: 0.3425\n",
      "Epoch 461/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1327 - mae: 0.1327 - val_loss: 0.3290 - val_mae: 0.3290\n",
      "Epoch 462/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1325 - mae: 0.1325 - val_loss: 0.3344 - val_mae: 0.3344\n",
      "Epoch 463/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1290 - mae: 0.1290 - val_loss: 0.3304 - val_mae: 0.3304\n",
      "Epoch 464/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1291 - mae: 0.1291 - val_loss: 0.3189 - val_mae: 0.3189\n",
      "Epoch 465/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1240 - mae: 0.1240 - val_loss: 0.3271 - val_mae: 0.3271\n",
      "Epoch 466/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1240 - mae: 0.1240 - val_loss: 0.3195 - val_mae: 0.3195\n",
      "Epoch 467/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1198 - mae: 0.1198 - val_loss: 0.3198 - val_mae: 0.3198\n",
      "Epoch 468/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1183 - mae: 0.1183 - val_loss: 0.3059 - val_mae: 0.3059\n",
      "Epoch 469/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1155 - mae: 0.1155 - val_loss: 0.3021 - val_mae: 0.3021\n",
      "Epoch 470/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1141 - mae: 0.1141 - val_loss: 0.3038 - val_mae: 0.3038\n",
      "Epoch 471/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1113 - mae: 0.1113 - val_loss: 0.2801 - val_mae: 0.2801\n",
      "Epoch 472/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1126 - mae: 0.1126 - val_loss: 0.2642 - val_mae: 0.2642\n",
      "Epoch 473/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1090 - mae: 0.1090 - val_loss: 0.2694 - val_mae: 0.2694\n",
      "Epoch 474/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1064 - mae: 0.1064 - val_loss: 0.2642 - val_mae: 0.2642\n",
      "Epoch 475/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1037 - mae: 0.1037 - val_loss: 0.2527 - val_mae: 0.2527\n",
      "Epoch 476/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1027 - mae: 0.1027 - val_loss: 0.2499 - val_mae: 0.2499\n",
      "Epoch 477/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0998 - mae: 0.0998 - val_loss: 0.2373 - val_mae: 0.2373\n",
      "Epoch 478/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0980 - mae: 0.0980 - val_loss: 0.2318 - val_mae: 0.2318\n",
      "Epoch 479/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0959 - mae: 0.0959 - val_loss: 0.2248 - val_mae: 0.2248\n",
      "Epoch 480/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0947 - mae: 0.0947 - val_loss: 0.2213 - val_mae: 0.2213\n",
      "Epoch 481/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0922 - mae: 0.0922 - val_loss: 0.1975 - val_mae: 0.1975\n",
      "Epoch 482/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0904 - mae: 0.0904 - val_loss: 0.1839 - val_mae: 0.1839\n",
      "Epoch 483/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0893 - mae: 0.0893 - val_loss: 0.1815 - val_mae: 0.1815\n",
      "Epoch 484/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0864 - mae: 0.0864 - val_loss: 0.1848 - val_mae: 0.1848\n",
      "Epoch 485/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0853 - mae: 0.0853 - val_loss: 0.1573 - val_mae: 0.1573\n",
      "Epoch 486/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0822 - mae: 0.0822 - val_loss: 0.1508 - val_mae: 0.1508\n",
      "Epoch 487/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0792 - mae: 0.0792 - val_loss: 0.1557 - val_mae: 0.1557\n",
      "Epoch 488/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0772 - mae: 0.0772 - val_loss: 0.1476 - val_mae: 0.1476\n",
      "Epoch 489/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0742 - mae: 0.0742 - val_loss: 0.1276 - val_mae: 0.1276\n",
      "Epoch 490/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0734 - mae: 0.0734 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 491/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0735 - mae: 0.0735 - val_loss: 0.1300 - val_mae: 0.1300\n",
      "Epoch 492/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0696 - mae: 0.0696 - val_loss: 0.1045 - val_mae: 0.1045\n",
      "Epoch 493/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0684 - mae: 0.0684 - val_loss: 0.1011 - val_mae: 0.1011\n",
      "Epoch 494/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0669 - mae: 0.0669 - val_loss: 0.1035 - val_mae: 0.1035\n",
      "Epoch 495/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0640 - mae: 0.0640 - val_loss: 0.0810 - val_mae: 0.0810\n",
      "Epoch 496/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0626 - mae: 0.0626 - val_loss: 0.0907 - val_mae: 0.0907\n",
      "Epoch 497/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0613 - mae: 0.0613 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 498/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0602 - mae: 0.0602 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 499/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0583 - mae: 0.0583 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 500/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0582 - mae: 0.0582 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 501/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 502/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 503/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 504/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0577 - mae: 0.0577 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 505/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0735 - val_mae: 0.0735\n",
      "Epoch 506/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0569 - mae: 0.0569 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 507/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0577 - mae: 0.0577 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 508/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0575 - mae: 0.0575 - val_loss: 0.0822 - val_mae: 0.0822\n",
      "Epoch 509/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0588 - mae: 0.0588 - val_loss: 0.0749 - val_mae: 0.0749\n",
      "Epoch 510/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0577 - mae: 0.0577 - val_loss: 0.0727 - val_mae: 0.0727\n",
      "Epoch 511/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.0743 - val_mae: 0.0743\n",
      "Epoch 512/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0583 - mae: 0.0583 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 513/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0582 - mae: 0.0582 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 514/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0569 - mae: 0.0569 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 515/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0573 - mae: 0.0573 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 516/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0573 - mae: 0.0573 - val_loss: 0.0713 - val_mae: 0.0713\n",
      "Epoch 517/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0572 - mae: 0.0572 - val_loss: 0.0703 - val_mae: 0.0703\n",
      "Epoch 518/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0576 - mae: 0.0576 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 519/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0577 - mae: 0.0577 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 520/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0573 - mae: 0.0573 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 521/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0569 - mae: 0.0569 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 522/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 523/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 524/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0560 - mae: 0.0560 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 525/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0565 - mae: 0.0565 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 526/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 527/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0725 - val_mae: 0.0725\n",
      "Epoch 528/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0573 - mae: 0.0573 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 529/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0560 - mae: 0.0560 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 530/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0576 - mae: 0.0576 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 531/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0586 - mae: 0.0586 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 532/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0600 - mae: 0.0600 - val_loss: 0.0736 - val_mae: 0.0736\n",
      "Epoch 533/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0744 - val_mae: 0.0744\n",
      "Epoch 534/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0577 - mae: 0.0577 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 535/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 536/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 537/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0715 - val_mae: 0.0715\n",
      "Epoch 538/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0560 - mae: 0.0560 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 539/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 540/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 541/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0566 - mae: 0.0566 - val_loss: 0.0742 - val_mae: 0.0742\n",
      "Epoch 542/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0565 - mae: 0.0565 - val_loss: 0.0724 - val_mae: 0.0724\n",
      "Epoch 543/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0575 - mae: 0.0575 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 544/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0584 - mae: 0.0584 - val_loss: 0.0773 - val_mae: 0.0773\n",
      "Epoch 545/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 546/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 547/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 548/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0582 - mae: 0.0582 - val_loss: 0.0750 - val_mae: 0.0750\n",
      "Epoch 549/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 550/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0552 - mae: 0.0552 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 551/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 552/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0554 - mae: 0.0554 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 553/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0710 - val_mae: 0.0710\n",
      "Epoch 554/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 555/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0548 - mae: 0.0548 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 556/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0549 - mae: 0.0549 - val_loss: 0.0714 - val_mae: 0.0714\n",
      "Epoch 557/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0544 - mae: 0.0544 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 558/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0554 - mae: 0.0554 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 559/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0565 - mae: 0.0565 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 560/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0548 - mae: 0.0548 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 561/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0546 - mae: 0.0546 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 562/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0552 - mae: 0.0552 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 563/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0550 - mae: 0.0550 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 564/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0575 - mae: 0.0575 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 565/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0582 - mae: 0.0582 - val_loss: 0.0805 - val_mae: 0.0805\n",
      "Epoch 566/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0597 - mae: 0.0597 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 567/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 568/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 569/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0551 - mae: 0.0551 - val_loss: 0.0720 - val_mae: 0.0720\n",
      "Epoch 570/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 571/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0575 - mae: 0.0575 - val_loss: 0.0731 - val_mae: 0.0731\n",
      "Epoch 572/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 573/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0549 - mae: 0.0549 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 574/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0542 - mae: 0.0542 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 575/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0540 - mae: 0.0540 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 576/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0537 - mae: 0.0537 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 577/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0549 - mae: 0.0549 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 578/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0539 - mae: 0.0539 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 579/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0549 - mae: 0.0549 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 580/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 581/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0564 - mae: 0.0564 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 582/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0553 - mae: 0.0553 - val_loss: 0.0769 - val_mae: 0.0769\n",
      "Epoch 583/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0565 - mae: 0.0565 - val_loss: 0.0699 - val_mae: 0.0699\n",
      "Epoch 584/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0538 - mae: 0.0538 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 585/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0545 - mae: 0.0545 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 586/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0543 - mae: 0.0543 - val_loss: 0.0739 - val_mae: 0.0739\n",
      "Epoch 587/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0548 - mae: 0.0548 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 588/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0533 - mae: 0.0533 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 589/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0534 - mae: 0.0534 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 590/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0538 - mae: 0.0538 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 591/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0544 - mae: 0.0544 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 592/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0550 - mae: 0.0550 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 593/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0551 - mae: 0.0551 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 594/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0535 - mae: 0.0535 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 595/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0531 - mae: 0.0531 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 596/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0525 - mae: 0.0525 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 597/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0519 - mae: 0.0519 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 598/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0524 - mae: 0.0524 - val_loss: 0.0759 - val_mae: 0.0759\n",
      "Epoch 599/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0541 - mae: 0.0541 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 600/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0526 - mae: 0.0526 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 601/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0525 - mae: 0.0525 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 602/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0525 - mae: 0.0525 - val_loss: 0.0722 - val_mae: 0.0722\n",
      "Epoch 603/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0536 - mae: 0.0536 - val_loss: 0.0747 - val_mae: 0.0747\n",
      "Epoch 604/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0537 - mae: 0.0537 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 605/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0528 - mae: 0.0528 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 606/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0529 - mae: 0.0529 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 607/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0530 - mae: 0.0530 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 608/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0526 - mae: 0.0526 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 609/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0534 - mae: 0.0534 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 610/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0525 - mae: 0.0525 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 611/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0524 - mae: 0.0524 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 612/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0531 - mae: 0.0531 - val_loss: 0.0698 - val_mae: 0.0698\n",
      "Epoch 613/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0523 - mae: 0.0523 - val_loss: 0.0701 - val_mae: 0.0701\n",
      "Epoch 614/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0531 - mae: 0.0531 - val_loss: 0.0750 - val_mae: 0.0750\n",
      "Epoch 615/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0573 - mae: 0.0573 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 616/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0523 - mae: 0.0523 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 617/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0539 - mae: 0.0539 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 618/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0526 - mae: 0.0526 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 619/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0532 - mae: 0.0532 - val_loss: 0.0758 - val_mae: 0.0758\n",
      "Epoch 620/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0530 - mae: 0.0530 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 621/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0521 - mae: 0.0521 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 622/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0520 - mae: 0.0520 - val_loss: 0.0731 - val_mae: 0.0731\n",
      "Epoch 623/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0518 - mae: 0.0518 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 624/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0525 - mae: 0.0525 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 625/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0526 - mae: 0.0526 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 626/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0531 - mae: 0.0531 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 627/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0534 - mae: 0.0534 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 628/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0515 - mae: 0.0515 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 629/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0512 - mae: 0.0512 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 630/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0510 - mae: 0.0510 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 631/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0530 - mae: 0.0530 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 632/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0532 - mae: 0.0532 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 633/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0515 - mae: 0.0515 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 634/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0509 - mae: 0.0509 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 635/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0507 - mae: 0.0507 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 636/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0507 - mae: 0.0507 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 637/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0499 - mae: 0.0499 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 638/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0509 - mae: 0.0509 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 639/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0507 - mae: 0.0507 - val_loss: 0.0718 - val_mae: 0.0718\n",
      "Epoch 640/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0531 - mae: 0.0531 - val_loss: 0.0812 - val_mae: 0.0812\n",
      "Epoch 641/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0546 - mae: 0.0546 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 642/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0523 - mae: 0.0523 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 643/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0501 - mae: 0.0501 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 644/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0500 - mae: 0.0500 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 645/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0505 - mae: 0.0505 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 646/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0499 - mae: 0.0499 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 647/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0504 - mae: 0.0504 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 648/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0509 - mae: 0.0509 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 649/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0499 - mae: 0.0499 - val_loss: 0.0737 - val_mae: 0.0737\n",
      "Epoch 650/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0502 - mae: 0.0502 - val_loss: 0.0706 - val_mae: 0.0706\n",
      "Epoch 651/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0495 - mae: 0.0495 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 652/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0491 - mae: 0.0491 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 653/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0494 - mae: 0.0494 - val_loss: 0.0699 - val_mae: 0.0699\n",
      "Epoch 654/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0499 - mae: 0.0499 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 655/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0508 - mae: 0.0508 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 656/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0492 - mae: 0.0492 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 657/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0507 - mae: 0.0507 - val_loss: 0.0767 - val_mae: 0.0767\n",
      "Epoch 658/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0509 - mae: 0.0509 - val_loss: 0.0722 - val_mae: 0.0722\n",
      "Epoch 659/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0510 - mae: 0.0510 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 660/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0506 - mae: 0.0506 - val_loss: 0.0740 - val_mae: 0.0740\n",
      "Epoch 661/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0531 - mae: 0.0531 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 662/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0519 - mae: 0.0519 - val_loss: 0.0746 - val_mae: 0.0746\n",
      "Epoch 663/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0515 - mae: 0.0515 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 664/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0517 - mae: 0.0517 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 665/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0498 - mae: 0.0498 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 666/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 667/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0496 - mae: 0.0496 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 668/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0492 - mae: 0.0492 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 669/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0495 - mae: 0.0495 - val_loss: 0.0726 - val_mae: 0.0726\n",
      "Epoch 670/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0505 - mae: 0.0505 - val_loss: 0.0769 - val_mae: 0.0769\n",
      "Epoch 671/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0498 - mae: 0.0498 - val_loss: 0.0706 - val_mae: 0.0706\n",
      "Epoch 672/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0484 - mae: 0.0484 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 673/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0488 - mae: 0.0488 - val_loss: 0.0759 - val_mae: 0.0759\n",
      "Epoch 674/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0496 - mae: 0.0496 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 675/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0506 - mae: 0.0506 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 676/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0512 - mae: 0.0512 - val_loss: 0.0759 - val_mae: 0.0759\n",
      "Epoch 677/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0512 - mae: 0.0512 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 678/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0511 - mae: 0.0511 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 679/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0511 - mae: 0.0511 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 680/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0511 - mae: 0.0511 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 681/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0504 - mae: 0.0504 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 682/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0506 - mae: 0.0506 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 683/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0520 - mae: 0.0520 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 684/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0506 - mae: 0.0506 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 685/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0481 - mae: 0.0481 - val_loss: 0.0705 - val_mae: 0.0705\n",
      "Epoch 686/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0489 - mae: 0.0489 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 687/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0480 - mae: 0.0480 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 688/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0478 - mae: 0.0478 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 689/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0485 - mae: 0.0485 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 690/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0482 - mae: 0.0482 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 691/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0503 - mae: 0.0503 - val_loss: 0.0778 - val_mae: 0.0778\n",
      "Epoch 692/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0493 - mae: 0.0493 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 693/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0478 - mae: 0.0478 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 694/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0508 - mae: 0.0508 - val_loss: 0.0775 - val_mae: 0.0775\n",
      "Epoch 695/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0483 - mae: 0.0483 - val_loss: 0.0718 - val_mae: 0.0718\n",
      "Epoch 696/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0474 - mae: 0.0474 - val_loss: 0.0770 - val_mae: 0.0770\n",
      "Epoch 697/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0498 - mae: 0.0498 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 698/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0489 - mae: 0.0489 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 699/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0478 - mae: 0.0478 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 700/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0488 - mae: 0.0488 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 701/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0506 - mae: 0.0506 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 702/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0500 - mae: 0.0500 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 703/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0482 - mae: 0.0482 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 704/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0506 - mae: 0.0506 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 705/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0477 - mae: 0.0477 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 706/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0481 - mae: 0.0481 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 707/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0483 - mae: 0.0483 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 708/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0476 - mae: 0.0476 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 709/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0491 - mae: 0.0491 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 710/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0474 - mae: 0.0474 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 711/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0469 - mae: 0.0469 - val_loss: 0.0716 - val_mae: 0.0716\n",
      "Epoch 712/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0472 - mae: 0.0472 - val_loss: 0.0717 - val_mae: 0.0717\n",
      "Epoch 713/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0480 - mae: 0.0480 - val_loss: 0.0646 - val_mae: 0.0646\n",
      "Epoch 714/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0473 - mae: 0.0473 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 715/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0467 - mae: 0.0467 - val_loss: 0.0731 - val_mae: 0.0731\n",
      "Epoch 716/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0481 - mae: 0.0481 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 717/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0466 - mae: 0.0466 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 718/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0468 - mae: 0.0468 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 719/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0481 - mae: 0.0481 - val_loss: 0.0759 - val_mae: 0.0759\n",
      "Epoch 720/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0473 - mae: 0.0473 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 721/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0475 - mae: 0.0475 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 722/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0477 - mae: 0.0477 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 723/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0470 - mae: 0.0470 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 724/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0475 - mae: 0.0475 - val_loss: 0.0715 - val_mae: 0.0715\n",
      "Epoch 725/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0475 - mae: 0.0475 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 726/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0501 - mae: 0.0501 - val_loss: 0.0731 - val_mae: 0.0731\n",
      "Epoch 727/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0477 - mae: 0.0477 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 728/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0470 - mae: 0.0470 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 729/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0486 - mae: 0.0486 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 730/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0459 - mae: 0.0459 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 731/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0464 - mae: 0.0464 - val_loss: 0.0744 - val_mae: 0.0744\n",
      "Epoch 732/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0459 - mae: 0.0459 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 733/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 734/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0460 - mae: 0.0460 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 735/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0466 - mae: 0.0466 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 736/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0470 - mae: 0.0470 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 737/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0473 - mae: 0.0473 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 738/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0466 - mae: 0.0466 - val_loss: 0.0722 - val_mae: 0.0722\n",
      "Epoch 739/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0465 - mae: 0.0465 - val_loss: 0.0721 - val_mae: 0.0721\n",
      "Epoch 740/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 741/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0449 - mae: 0.0449 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 742/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0453 - mae: 0.0453 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 743/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0447 - mae: 0.0447 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 744/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0458 - mae: 0.0458 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 745/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0455 - mae: 0.0455 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 746/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0461 - mae: 0.0461 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 747/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0460 - mae: 0.0460 - val_loss: 0.0720 - val_mae: 0.0720\n",
      "Epoch 748/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0476 - mae: 0.0476 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 749/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0450 - mae: 0.0450 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 750/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0452 - mae: 0.0452 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 751/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0447 - mae: 0.0447 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 752/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0445 - mae: 0.0445 - val_loss: 0.0701 - val_mae: 0.0701\n",
      "Epoch 753/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0460 - mae: 0.0460 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 754/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0455 - mae: 0.0455 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 755/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0450 - mae: 0.0450 - val_loss: 0.0703 - val_mae: 0.0703\n",
      "Epoch 756/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0457 - mae: 0.0457 - val_loss: 0.0790 - val_mae: 0.0790\n",
      "Epoch 757/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0465 - mae: 0.0465 - val_loss: 0.0714 - val_mae: 0.0714\n",
      "Epoch 758/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0481 - mae: 0.0481 - val_loss: 0.0851 - val_mae: 0.0851\n",
      "Epoch 759/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0463 - mae: 0.0463 - val_loss: 0.0773 - val_mae: 0.0773\n",
      "Epoch 760/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0465 - mae: 0.0465 - val_loss: 0.0803 - val_mae: 0.0803\n",
      "Epoch 761/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0464 - mae: 0.0464 - val_loss: 0.0766 - val_mae: 0.0766\n",
      "Epoch 762/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0454 - mae: 0.0454 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 763/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0465 - mae: 0.0465 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 764/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0501 - mae: 0.0501 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 765/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0469 - mae: 0.0469 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 766/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0471 - mae: 0.0471 - val_loss: 0.0718 - val_mae: 0.0718\n",
      "Epoch 767/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0454 - mae: 0.0454 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 768/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0455 - mae: 0.0455 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 769/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0453 - mae: 0.0453 - val_loss: 0.0741 - val_mae: 0.0741\n",
      "Epoch 770/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0478 - mae: 0.0478 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 771/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0447 - mae: 0.0447 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 772/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0461 - mae: 0.0461 - val_loss: 0.0725 - val_mae: 0.0725\n",
      "Epoch 773/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0461 - mae: 0.0461 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 774/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0444 - mae: 0.0444 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 775/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0448 - mae: 0.0448 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 776/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0441 - mae: 0.0441 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 777/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0448 - mae: 0.0448 - val_loss: 0.0778 - val_mae: 0.0778\n",
      "Epoch 778/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0448 - mae: 0.0448 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 779/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0469 - mae: 0.0469 - val_loss: 0.0752 - val_mae: 0.0752\n",
      "Epoch 780/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0453 - mae: 0.0453 - val_loss: 0.0706 - val_mae: 0.0706\n",
      "Epoch 781/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0443 - mae: 0.0443 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 782/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0445 - mae: 0.0445 - val_loss: 0.0739 - val_mae: 0.0739\n",
      "Epoch 783/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0435 - mae: 0.0435 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 784/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0428 - mae: 0.0428 - val_loss: 0.0742 - val_mae: 0.0742\n",
      "Epoch 785/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0437 - mae: 0.0437 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 786/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.0432 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 787/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0427 - mae: 0.0427 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 788/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0429 - mae: 0.0429 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 789/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0428 - mae: 0.0428 - val_loss: 0.0681 - val_mae: 0.0681\n",
      "Epoch 790/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.0431 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 791/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0429 - mae: 0.0429 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 792/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0448 - mae: 0.0448 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 793/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0462 - mae: 0.0462 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 794/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0458 - mae: 0.0458 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 795/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0473 - mae: 0.0473 - val_loss: 0.0625 - val_mae: 0.0625\n",
      "Epoch 796/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0459 - mae: 0.0459 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 797/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0484 - mae: 0.0484 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 798/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0457 - mae: 0.0457 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 799/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0453 - mae: 0.0453 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 800/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0428 - mae: 0.0428 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 801/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0422 - mae: 0.0422 - val_loss: 0.0711 - val_mae: 0.0711\n",
      "Epoch 802/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0440 - mae: 0.0440 - val_loss: 0.0725 - val_mae: 0.0725\n",
      "Epoch 803/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0425 - mae: 0.0425 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 804/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0424 - mae: 0.0424 - val_loss: 0.0710 - val_mae: 0.0710\n",
      "Epoch 805/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0452 - mae: 0.0452 - val_loss: 0.0643 - val_mae: 0.0643\n",
      "Epoch 806/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0445 - mae: 0.0445 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 807/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0439 - mae: 0.0439 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 808/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0727 - val_mae: 0.0727\n",
      "Epoch 809/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0455 - mae: 0.0455 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 810/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0427 - mae: 0.0427 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 811/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0416 - mae: 0.0416 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 812/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0415 - mae: 0.0415 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 813/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.0419 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 814/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0420 - mae: 0.0420 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 815/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0429 - mae: 0.0429 - val_loss: 0.0785 - val_mae: 0.0785\n",
      "Epoch 816/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0445 - mae: 0.0445 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 817/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0430 - mae: 0.0430 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 818/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0428 - mae: 0.0428 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 819/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0426 - mae: 0.0426 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 820/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0441 - mae: 0.0441 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 821/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.0441 - val_loss: 0.0768 - val_mae: 0.0768\n",
      "Epoch 822/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.0432 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 823/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0440 - mae: 0.0440 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 824/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0423 - mae: 0.0423 - val_loss: 0.0730 - val_mae: 0.0730\n",
      "Epoch 825/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0422 - mae: 0.0422 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 826/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0417 - mae: 0.0417 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 827/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0411 - mae: 0.0411 - val_loss: 0.0696 - val_mae: 0.0696\n",
      "Epoch 828/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0434 - mae: 0.0434 - val_loss: 0.0774 - val_mae: 0.0774\n",
      "Epoch 829/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0420 - mae: 0.0420 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 830/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0408 - mae: 0.0408 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 831/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0424 - mae: 0.0424 - val_loss: 0.0719 - val_mae: 0.0719\n",
      "Epoch 832/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0410 - mae: 0.0410 - val_loss: 0.0709 - val_mae: 0.0709\n",
      "Epoch 833/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0409 - mae: 0.0409 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 834/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0417 - mae: 0.0417 - val_loss: 0.0714 - val_mae: 0.0714\n",
      "Epoch 835/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0426 - mae: 0.0426 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 836/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0410 - mae: 0.0410 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 837/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0404 - mae: 0.0404 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 838/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0412 - mae: 0.0412 - val_loss: 0.0694 - val_mae: 0.0694\n",
      "Epoch 839/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0431 - val_loss: 0.0822 - val_mae: 0.0822\n",
      "Epoch 840/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0431 - val_loss: 0.0708 - val_mae: 0.0708\n",
      "Epoch 841/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0438 - mae: 0.0438 - val_loss: 0.0773 - val_mae: 0.0773\n",
      "Epoch 842/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0412 - mae: 0.0412 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 843/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0401 - mae: 0.0401 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 844/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0396 - mae: 0.0396 - val_loss: 0.0696 - val_mae: 0.0696\n",
      "Epoch 845/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0407 - mae: 0.0407 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 846/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0406 - mae: 0.0406 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 847/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0417 - mae: 0.0417 - val_loss: 0.0680 - val_mae: 0.0680\n",
      "Epoch 848/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0409 - mae: 0.0409 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 849/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0408 - mae: 0.0408 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 850/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0396 - mae: 0.0396 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 851/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0397 - mae: 0.0397 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 852/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0398 - mae: 0.0398 - val_loss: 0.0764 - val_mae: 0.0764\n",
      "Epoch 853/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0416 - mae: 0.0416 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 854/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0405 - mae: 0.0405 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 855/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0413 - mae: 0.0413 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 856/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0398 - mae: 0.0398 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 857/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0395 - mae: 0.0395 - val_loss: 0.0713 - val_mae: 0.0713\n",
      "Epoch 858/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0408 - mae: 0.0408 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 859/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0391 - mae: 0.0391 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 860/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0401 - mae: 0.0401 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 861/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0405 - mae: 0.0405 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 862/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0404 - mae: 0.0404 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 863/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0393 - mae: 0.0393 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 864/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0401 - mae: 0.0401 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 865/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0391 - mae: 0.0391 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 866/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0391 - mae: 0.0391 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 867/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0414 - mae: 0.0414 - val_loss: 0.0738 - val_mae: 0.0738\n",
      "Epoch 868/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0417 - mae: 0.0417 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 869/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0396 - mae: 0.0396 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 870/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0386 - mae: 0.0386 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 871/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0389 - mae: 0.0389 - val_loss: 0.0662 - val_mae: 0.0662\n",
      "Epoch 872/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0389 - mae: 0.0389 - val_loss: 0.0699 - val_mae: 0.0699\n",
      "Epoch 873/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0388 - mae: 0.0388 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 874/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0384 - mae: 0.0384 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 875/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0410 - mae: 0.0410 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 876/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0415 - mae: 0.0415 - val_loss: 0.0779 - val_mae: 0.0779\n",
      "Epoch 877/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0414 - mae: 0.0414 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 878/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.0419 - val_loss: 0.0757 - val_mae: 0.0757\n",
      "Epoch 879/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0393 - mae: 0.0393 - val_loss: 0.0695 - val_mae: 0.0695\n",
      "Epoch 880/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0401 - mae: 0.0401 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 881/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0424 - mae: 0.0424 - val_loss: 0.0725 - val_mae: 0.0725\n",
      "Epoch 882/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0409 - mae: 0.0409 - val_loss: 0.0731 - val_mae: 0.0731\n",
      "Epoch 883/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0421 - mae: 0.0421 - val_loss: 0.0737 - val_mae: 0.0737\n",
      "Epoch 884/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0396 - mae: 0.0396 - val_loss: 0.0775 - val_mae: 0.0775\n",
      "Epoch 885/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0392 - mae: 0.0392 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 886/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0388 - mae: 0.0388 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 887/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0396 - mae: 0.0396 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 888/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0391 - mae: 0.0391 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 889/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0392 - mae: 0.0392 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 890/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0394 - mae: 0.0394 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 891/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0392 - mae: 0.0392 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 892/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0388 - mae: 0.0388 - val_loss: 0.0696 - val_mae: 0.0696\n",
      "Epoch 893/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0385 - mae: 0.0385 - val_loss: 0.0749 - val_mae: 0.0749\n",
      "Epoch 894/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0421 - mae: 0.0421 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 895/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0396 - mae: 0.0396 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 896/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0405 - mae: 0.0405 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 897/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0390 - mae: 0.0390 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 898/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0392 - mae: 0.0392 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 899/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0396 - mae: 0.0396 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 900/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0381 - mae: 0.0381 - val_loss: 0.0706 - val_mae: 0.0706\n",
      "Epoch 901/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0379 - mae: 0.0379 - val_loss: 0.0721 - val_mae: 0.0721\n",
      "Epoch 902/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0378 - mae: 0.0378 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 903/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0378 - mae: 0.0378 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 904/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0389 - mae: 0.0389 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 905/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0371 - mae: 0.0371 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 906/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0388 - mae: 0.0388 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 907/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0396 - mae: 0.0396 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 908/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0377 - mae: 0.0377 - val_loss: 0.0719 - val_mae: 0.0719\n",
      "Epoch 909/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0372 - mae: 0.0372 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 910/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0371 - mae: 0.0371 - val_loss: 0.0661 - val_mae: 0.0661\n",
      "Epoch 911/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0366 - mae: 0.0366 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 912/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0372 - mae: 0.0372 - val_loss: 0.0717 - val_mae: 0.0717\n",
      "Epoch 913/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0384 - mae: 0.0384 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 914/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0375 - mae: 0.0375 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 915/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0371 - mae: 0.0371 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 916/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0378 - mae: 0.0378 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 917/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.0363 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 918/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0368 - mae: 0.0368 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 919/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0376 - mae: 0.0376 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 920/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0372 - mae: 0.0372 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 921/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0428 - mae: 0.0428 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 922/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0372 - mae: 0.0372 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 923/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0378 - mae: 0.0378 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 924/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0367 - mae: 0.0367 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 925/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0377 - mae: 0.0377 - val_loss: 0.0719 - val_mae: 0.0719\n",
      "Epoch 926/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0367 - mae: 0.0367 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 927/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0361 - mae: 0.0361 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 928/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0358 - mae: 0.0358 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 929/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0361 - mae: 0.0361 - val_loss: 0.0697 - val_mae: 0.0697\n",
      "Epoch 930/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0363 - mae: 0.0363 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 931/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0364 - mae: 0.0364 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 932/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0360 - mae: 0.0360 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 933/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0358 - mae: 0.0358 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 934/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0354 - mae: 0.0354 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 935/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0372 - mae: 0.0372 - val_loss: 0.0699 - val_mae: 0.0699\n",
      "Epoch 936/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0370 - mae: 0.0370 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 937/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0354 - mae: 0.0354 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 938/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0363 - mae: 0.0363 - val_loss: 0.0726 - val_mae: 0.0726\n",
      "Epoch 939/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0403 - mae: 0.0403 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 940/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0413 - mae: 0.0413 - val_loss: 0.0699 - val_mae: 0.0699\n",
      "Epoch 941/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0403 - mae: 0.0403 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 942/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0400 - mae: 0.0400 - val_loss: 0.0702 - val_mae: 0.0702\n",
      "Epoch 943/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0377 - mae: 0.0377 - val_loss: 0.0684 - val_mae: 0.0684\n",
      "Epoch 944/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0354 - mae: 0.0354 - val_loss: 0.0677 - val_mae: 0.0677\n",
      "Epoch 945/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0347 - mae: 0.0347 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 946/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0364 - mae: 0.0364 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 947/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0374 - mae: 0.0374 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 948/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0369 - mae: 0.0369 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 949/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0364 - mae: 0.0364 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 950/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0355 - mae: 0.0355 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 951/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0360 - mae: 0.0360 - val_loss: 0.0642 - val_mae: 0.0642\n",
      "Epoch 952/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.0360 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 953/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0346 - mae: 0.0346 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 954/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0356 - mae: 0.0356 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 955/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0371 - mae: 0.0371 - val_loss: 0.0769 - val_mae: 0.0769\n",
      "Epoch 956/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0356 - mae: 0.0356 - val_loss: 0.0750 - val_mae: 0.0750\n",
      "Epoch 957/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0360 - mae: 0.0360 - val_loss: 0.0780 - val_mae: 0.0780\n",
      "Epoch 958/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0374 - mae: 0.0374 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 959/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0350 - mae: 0.0350 - val_loss: 0.0660 - val_mae: 0.0660\n",
      "Epoch 960/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0348 - mae: 0.0348 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 961/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0347 - mae: 0.0347 - val_loss: 0.0683 - val_mae: 0.0683\n",
      "Epoch 962/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0354 - mae: 0.0354 - val_loss: 0.0732 - val_mae: 0.0732\n",
      "Epoch 963/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0353 - mae: 0.0353 - val_loss: 0.0733 - val_mae: 0.0733\n",
      "Epoch 964/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0357 - mae: 0.0357 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 965/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0360 - mae: 0.0360 - val_loss: 0.0754 - val_mae: 0.0754\n",
      "Epoch 966/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0345 - mae: 0.0345 - val_loss: 0.0676 - val_mae: 0.0676\n",
      "Epoch 967/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0347 - mae: 0.0347 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 968/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0342 - mae: 0.0342 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 969/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0341 - mae: 0.0341 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 970/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0347 - mae: 0.0347 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 971/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0346 - mae: 0.0346 - val_loss: 0.0732 - val_mae: 0.0732\n",
      "Epoch 972/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0346 - mae: 0.0346 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 973/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0338 - mae: 0.0338 - val_loss: 0.0689 - val_mae: 0.0689\n",
      "Epoch 974/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0338 - mae: 0.0338 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 975/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0349 - mae: 0.0349 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 976/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0341 - mae: 0.0341 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 977/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0343 - mae: 0.0343 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 978/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0343 - mae: 0.0343 - val_loss: 0.0715 - val_mae: 0.0715\n",
      "Epoch 979/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0363 - mae: 0.0363 - val_loss: 0.0700 - val_mae: 0.0700\n",
      "Epoch 980/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0354 - mae: 0.0354 - val_loss: 0.0781 - val_mae: 0.0781\n",
      "Epoch 981/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0368 - mae: 0.0368 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 982/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0375 - mae: 0.0375 - val_loss: 0.0754 - val_mae: 0.0754\n",
      "Epoch 983/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0370 - mae: 0.0370 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 984/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0359 - mae: 0.0359 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 985/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0341 - mae: 0.0341 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 986/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0344 - mae: 0.0344 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 987/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0344 - mae: 0.0344 - val_loss: 0.0714 - val_mae: 0.0714\n",
      "Epoch 988/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.0330 - val_loss: 0.0688 - val_mae: 0.0688\n",
      "Epoch 989/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0325 - mae: 0.0325 - val_loss: 0.0726 - val_mae: 0.0726\n",
      "Epoch 990/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.0335 - val_loss: 0.0756 - val_mae: 0.0756\n",
      "Epoch 991/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0351 - mae: 0.0351 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 992/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0337 - mae: 0.0337 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 993/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0331 - mae: 0.0331 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 994/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0337 - mae: 0.0337 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 995/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0357 - mae: 0.0357 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 996/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0331 - mae: 0.0331 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 997/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0328 - mae: 0.0328 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 998/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0336 - mae: 0.0336 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 999/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.0329 - val_loss: 0.0723 - val_mae: 0.0723\n",
      "Epoch 1000/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0321 - mae: 0.0321 - val_loss: 0.0671 - val_mae: 0.0671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "training_dataset = pd.DataFrame([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 2],\n",
    "    [2, 0, 2],\n",
    "    [2, 1, 3],\n",
    "    [3, 0, 3],\n",
    "    [3, 1, 4],\n",
    "    [4, 0, 4],\n",
    "    [4, 1, 5]\n",
    "])\n",
    "\n",
    "x_train = training_dataset.iloc[:, 0:2] # ? iets van alle [0]'s naar 1 array?\n",
    "y_train = training_dataset.iloc[:, 2] # ? same maar dan [1]'s?\n",
    "\n",
    "test_dataset = pd.DataFrame([\n",
    "    [0, 3, 3],\n",
    "    [1, 3, 4],\n",
    "    [2, 3, 5],\n",
    "    [3, 2, 5],\n",
    "    [0, 4, 4]\n",
    "])\n",
    "\n",
    "x_test = test_dataset.iloc[:, 0:2] # ? iets van alle [0]'s naar 1 array?\n",
    "y_test = test_dataset.iloc[:, 2] # ? same maar dan [1]'s?\n",
    "\n",
    "model = Sequential() # zet lagen model op\n",
    "model.add(Dense(3, activation='relu', input_dim=2)) # add input laag\n",
    "model.add(Dense(1)) # output laag (nummer)\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae']) # mae is een manier van error bepalen, ?, ?\n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=1000, batch_size=1) # input 1, input 2, test met test data, training cycles, 100 rows trainen/testen voordat ie zichzelf aanpast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "err = hist.history['mae']\n",
    "val_err = hist.history['val_mae']\n",
    "epochs = range(1, len(err) + 1)\n",
    "\n",
    "plt.plot(epochs, err, '-', label='Training MAE')\n",
    "plt.plot(epochs, val_err, ':', label='Validation MAE')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend(loc='upper right')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will try to add 3 + 9: 12\n"
     ]
    }
   ],
   "source": [
    "# two numbers to add (addition must not exceed 5)\n",
    "x_pred = 3\n",
    "y_pred = 9\n",
    "\n",
    "prediction = model.predict(np.array([[x_pred, y_pred]]))\n",
    "\n",
    "print(f\"The model will try to add {x_pred} + {y_pred}:\", round(prediction[0][0])) # predict met een array van eigen inputs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d04e34086118c6dc54107cb071493bddf86b7700e0866e4e48f307afaf7f57f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
